# ChatRagi Documentation Overview

Welcome to the documentation hub for **ChatRagi** ‚Äî your local Retrieval-Augmented Generation (RAG) chatbot framework.

This folder contains detailed guides for understanding, setting up, and extending various parts of the system.

---

## üìÇ Available Documentation

| Document | Description |
|:---------|:------------|
| [Architecture Overview](architecture.md) | High-level system diagrams showing ingestion, retrieval, and LLM interaction flows |
| [File Watcher Service](File-Watcher-README.md) | How the document ingestion service monitors and indexes new files automatically |
| [Web Application Backend](App-README.md) | API endpoints, server setup, and backend responsibilities for running the chatbot interface |
| [Configuration Overview](Config-README.md) | Central settings (paths, models, flags) and how to override them |
| [Running LLMs Locally](Running-LLMs-Locally-README.md) | Setup instructions for Ollama, local LLM models, and embedding models |
| [Known Issues](KNOWN_ISSUES.md) | List of known bugs, limitations, and workarounds |

---

## üõ†Ô∏è Development Status

ChatRagi is currently under active private development.  
Contributions are not open yet, but public participation is planned for a future release.

---

## üîó Related Resources

- Main project repo: [ChatRagi GitHub](https://github.com/sssethi-dg/chatragi) (private for now)
- Ollama documentation: [https://ollama.com/](https://ollama.com/)
- ChromaDB documentation: [https://docs.trychroma.com/](https://docs.trychroma.com/)

---

## üìã Summary

These documents are designed to be modular ‚Äî you can start with just the Web App setup, dive deeper into the ingestion pipeline, or learn how to customize local models as needed.

Thank you for exploring ChatRagi!